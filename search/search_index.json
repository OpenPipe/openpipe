{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"An Open Source Data Integration Toolkit A human friendly data-oriented language hello.yaml start : - insert : name : John Doe age : 80 - print : - print : Hello $name$ your age is $age - 41$ To learn more about the language, check the language documentation . A simple command line tool openpipe run hello.yaml {'name': 'John Doe', 'age': 80} Hello John Doe your age is 39 To learn more about the tool, check the tool documentation .","title":"Home"},{"location":"#an-open-source-data-integration-toolkit","text":"","title":"An Open Source Data Integration Toolkit"},{"location":"#a-human-friendly-data-oriented-language","text":"hello.yaml start : - insert : name : John Doe age : 80 - print : - print : Hello $name$ your age is $age - 41$ To learn more about the language, check the language documentation .","title":"A human friendly data-oriented language"},{"location":"#a-simple-command-line-tool","text":"openpipe run hello.yaml {'name': 'John Doe', 'age': 80} Hello John Doe your age is 39 To learn more about the tool, check the tool documentation .","title":"A simple command line tool"},{"location":"Windows_Python_3_Install/","text":"Note This document shows downloading and installing Python 3.7.0 (32 bits) on Windows 7 in Summer 2018. You should download and install the latest version of Python. The current latest (as of Winter 2019) is Python 3.7.2, 64 bits. Downloading Click Python Download . The following page will appear in your browser: Click the Download Python 3.7.0 button. The file named python-3.7.0.exe should start downloading into your standard download folder. Installing Once the download is completed, double-click the file icon to open it, the following warning will be shown: Click Run A Python 3.7 (32-bit) Setup pop-up window will appear: Ensure that the Install launcher for all users (recommended) and the Add Python 3.7 to PATH checkboxes at the bottom are checked. Highlight the Install Now (or Upgrade Now ) message, and then click it. A User Account Control pop-up window will appear, posing the question Do you want the allow the following program to make changes to this computer: Click the Yes button. A new Python 3.7 Setup pop-up window will appear with a Setup Progress message and a progress bar: During installation, it will show the various components it is installing and move the progress bar towards completion. Soon, a new Python 3.7 Setup pop-up window will appear with a Setup was successfully message: Click the Close button. Python should now be installed. This document was based on: https://www.ics.uci.edu/~pattis/common/handouts/pythoneclipsejava/python.html","title":"Windows Python 3 Install"},{"location":"Windows_Python_3_Install/#downloading","text":"Click Python Download . The following page will appear in your browser: Click the Download Python 3.7.0 button. The file named python-3.7.0.exe should start downloading into your standard download folder.","title":"Downloading"},{"location":"Windows_Python_3_Install/#installing","text":"Once the download is completed, double-click the file icon to open it, the following warning will be shown: Click Run A Python 3.7 (32-bit) Setup pop-up window will appear: Ensure that the Install launcher for all users (recommended) and the Add Python 3.7 to PATH checkboxes at the bottom are checked. Highlight the Install Now (or Upgrade Now ) message, and then click it. A User Account Control pop-up window will appear, posing the question Do you want the allow the following program to make changes to this computer: Click the Yes button. A new Python 3.7 Setup pop-up window will appear with a Setup Progress message and a progress bar: During installation, it will show the various components it is installing and move the progress bar towards completion. Soon, a new Python 3.7 Setup pop-up window will appear with a Setup was successfully message: Click the Close button. Python should now be installed. This document was based on: https://www.ics.uci.edu/~pattis/common/handouts/pythoneclipsejava/python.html","title":"Installing"},{"location":"1.0/action-devel/","text":"Openpipe Action Development This document provides is a quick reference for developers planning to write openpipe action modules. Example Action Code \"\"\" Print content to the standard output \"\"\" from openpipe.pipeline.engine import ActionRuntime class Action ( ActionRuntime ): optional_config = \"\"\" '{ _ }' # The content to be printed, default is the input item ('{ _ }') \"\"\" def on_input ( self , item ): print ( self . config ) # Print item to the console self . put ( item ) # No change to the data stream, input -> output Example Action Usage start : print : Hello world Introduction An openpipe action is a regular Python module with the following requirements: Must provide a docstring with a short description, the first line will be displayed on openpipe help Must provide a class named Action , which: Must be derived from the ActionRuntime class May provide the following class attributes to be handled by the pipeline engine: required_config : string with YAML describing required config optional_config : string with YAML describing optional config May provide the following class methods to be invoked by the pipeline engine: on_start(self, config) : invoked when the pipeline is started on_input(self, item) : invoked when an input item is received may use self.put(item) once or multiple times to produce items on_finish(self, reason) : invoked when the pipeline is finished","title":"Actions Development"},{"location":"1.0/action-devel/#openpipe-action-development","text":"This document provides is a quick reference for developers planning to write openpipe action modules.","title":"Openpipe Action Development"},{"location":"1.0/action-devel/#example-action-code","text":"\"\"\" Print content to the standard output \"\"\" from openpipe.pipeline.engine import ActionRuntime class Action ( ActionRuntime ): optional_config = \"\"\" '{ _ }' # The content to be printed, default is the input item ('{ _ }') \"\"\" def on_input ( self , item ): print ( self . config ) # Print item to the console self . put ( item ) # No change to the data stream, input -> output","title":"Example Action Code"},{"location":"1.0/action-devel/#example-action-usage","text":"start : print : Hello world","title":"Example Action Usage"},{"location":"1.0/action-devel/#introduction","text":"An openpipe action is a regular Python module with the following requirements: Must provide a docstring with a short description, the first line will be displayed on openpipe help Must provide a class named Action , which: Must be derived from the ActionRuntime class May provide the following class attributes to be handled by the pipeline engine: required_config : string with YAML describing required config optional_config : string with YAML describing optional config May provide the following class methods to be invoked by the pipeline engine: on_start(self, config) : invoked when the pipeline is started on_input(self, item) : invoked when an input item is received may use self.put(item) once or multiple times to produce items on_finish(self, reason) : invoked when the pipeline is finished","title":"Introduction"},{"location":"1.0/actions/","text":"Data Sourcing Action Purpose empty Produce \"True\" when the input is empty execute Execute a command and produce the execution result insert Insert an item insert path split Split a path to 'directory' and 'file' components iterate Iterate the configuration item producing each element merge Merge input and configuration items queue Produce a list by queuing items read from clock Produce the system clock time at regular intervals read from file Produce metadata/content from a local or remote file read from file list Produce the list of files matching a pattern read from file status Get path status information read from openpipe actions Produce the list of available action actions read from url Produce metadata/content from an URL Data Selection Action Purpose select Select input items based on a conditional expression select subset Select a subset of data from a dictionary input Data Transformation Action Purpose decompress Decompress gzip input item reduce Reduce a complex item type into a simpler structure transform using csv Produce dictionary from CSV line based input transform using regex assign Build a dictionary from a key/map regex group expression Data Analysis Action Purpose count Count the number of elements received group by stats Produce statistics by grouping input items by keys pprint Pretty print an item print Print an item transform using terminaltables Produce a text table Data Control Action Purpose limit Limit the max number of items sent to the next action send to segment Send a copy of the input item to other segment(s) tag Tag input item with the provided configuration tag item tag key Tag a key or list of keys Data Export Action Purpose write to file Write item to a file Data Manipulation Action Purpose drop Remove some keys from the input item sort Sort items by keys update Update values depending on conditional expressions update using case replace Update field values using case match update using key mapping Map values from source keys to values on target keys update using string replace Replace some phrase with other phrase Data Validation Action Purpose assert Asserts that input matches the config provided item Data Sourcing empty Produce \"True\" when the input is empty Module source: openpipe/actions/empty_.py execute Execute a command and produce the execution result Required Configuration - execute : cmd : # The command to be executed Optional Configuration shell : True # Execute the command as parameters to a system shell output_as_text : True # Output the command output as text fail_on_error : True # Abort pipeline if exit code is not zero Module source: openpipe/actions/execute_.py insert Insert an item Required Configuration - insert : # Item to be produced as an output Module source: openpipe/actions/insert_.py insert path split Split a path to 'directory' and 'file' components Optional Configuration - insert path split : '{ _ }' # The path to produce the director name from Module source: openpipe/actions/insert/path/split_.py iterate Iterate the configuration item producing each element Optional Configuration - iterate : '{ _ }' # The item to be iterated over Module source: openpipe/actions/iterate_.py merge Merge input and configuration items Optional Configuration - merge : $_tag$ # The item to merge with Module source: openpipe/actions/merge_.py queue Produce a list by queuing items Required Configuration - queue : The count of items to be queued before producing a list. If set to 0 all items are queued until the input ends Module source: openpipe/actions/queue_.py read from clock Produce the system clock time at regular intervals Optional Configuration - read from clock : interval : 0 # Pause time between insertions, 0 means forever max_count : 1 # Max number of item insertions Module source: openpipe/actions/read/from/clock_.py read from file Produce metadata/content from a local or remote file Required Configuration - read from file : path : # Local path or HTTP/HTTPS/FTP url Optional Configuration # The mime_type will be used by the action to identify and automatically # decode the file content. # With the default value of 'auto' the action will try to guess the # mime type based on the content header or file extension. mime_type : auto # The following option is only applicable to local filenames auto_expand_home : True # Expand '~' on path to user home dir Module source: openpipe/actions/read/from/file_.py read from file list Produce the list of files matching a pattern Optional Configuration - read from file list : '{ _ }' # The pattern to be used for matching Module source: openpipe/actions/read/from/file/list_.py read from file status Get path status information Optional Configuration - read from file status : '{ _ }' # Path of the file to be checked Module source: openpipe/actions/read/from/file/status_.py read from openpipe actions Produce the list of available action actions Optional Configuration - read from openpipe actions : '{ _ }' # The item to be printed, the default is the input item Module source: openpipe/actions/read/from/openpipe/actions_.py read from url Produce metadata/content from an URL Required Configuration - read from url : url : # HTTP/HTTPS/FTP url Optional Configuration # The mime_type will be used by the action to identify and automatically # decode the file content. # With the default value of 'auto' the action will try to guess the # mime type based on the content header or file extension. mime_type : auto # The following options are only relevant for HTTP/HTTPS/FTP paths timeout : 30 # Global timeout (in secs) for the operation ignore_http_errors : False # Ignore HTTP errors replies user_agent : curl/7.64.0 # User-agent to use on HTTP requests Module source: openpipe/actions/read/from/url_.py Data Selection select Select input items based on a conditional expression Required Configuration - select : # Boolean Expression # Items are only copied to next action only when the expression evaluates # to True Module source: openpipe/actions/select_.py select subset Select a subset of data from a dictionary input Required Configuration - select subset : # YAML describing the elements to be retrieved Module source: openpipe/actions/select/subset_.py Data Transformation decompress Decompress gzip input item Optional Configuration - decompress : path : \"\" # If not provided the input item is used type : gzip # the type to decompress Module source: openpipe/actions/decompress_.py reduce Reduce a complex item type into a simpler structure Optional Configuration - reduce : '{ _ }' # The target reduction format Module source: openpipe/actions/reduce_.py transform using csv Produce dictionary from CSV line based input Optional Configuration - transform using csv : delimiter : \",\" # One-character string used to separate fields quotechar : '\"' # One-character to wrap string values auto_number : False # Attempt to convert fields to numbers ignore_errors : False # Ignore conversion errors field_list : [] # Optional list of fields to be used as headers Module source: openpipe/actions/transform/using/csv_.py transform using regex assign Build a dictionary from a key/map regex group expression Required Configuration - transform using regex assign : regex : # A regex expression that must match two groups: # (group1) (group2) Module source: openpipe/actions/transform/using/regex/assign_.py Data Analysis count Count the number of elements received Optional Configuration - count : group_by : \"\" # Expression to use for count aggregation Module source: openpipe/actions/count_.py group by stats Produce statistics by grouping input items by keys Required Configuration - group by stats : keys : # List of keys to be used for grouping Optional Configuration stats : [ sum , count , max , min ] # List of stats to obtain sorted_fields : [] # When these fields change, produce the sort Module source: openpipe/actions/group/by/stats_.py pprint Pretty print an item Optional Configuration - pprint : '{ _ }' # The content to be pretty printed Module source: openpipe/actions/pprint_.py print Print an item Optional Configuration - print : \"{_}\" # The item to be printed, the default is the input item Module source: openpipe/actions/print_.py transform using terminaltables Produce a text table Required Configuration - transform using terminaltables : header : # List of labels to be used as column headers keys : # List of keys to be used or row elements Module source: openpipe/actions/transform/using/terminaltables_.py Data Control limit Limit the max number of items sent to the next action Required Configuration - limit : max : # The max number of items sent to next action Module source: openpipe/actions/limit_.py send to segment Send a copy of the input item to other segment(s) Required Configuration - send to segment : name : # Name or list of of segments to receive the item Optional Configuration when : \"\" # An expression that should result in a boolean # If `when` is set, item will only be copied to the segment(s) # when it evaluates to True. And sent to next action when it evaluates # to False Module source: openpipe/actions/send/to/segment_.py tag Tag input item with the provided configuration tag item Optional Configuration - tag : '{ _ }' # Default is to tag the entire input item Module source: openpipe/actions/tag_.py tag key Tag a key or list of keys Required Configuration - tag key : name : # The name or list of names for the keys to be tagged Module source: openpipe/actions/tag/key_.py Data Export write to file Write item to a file Required Configuration - write to file : path : # Filename of the file to create/overwrite/append Optional Configuration content : '{ _ }' # Content to be written to the file mode : \"w\" # Open file mode (write/append) close_on_item : False # Force file close after each received item Module source: openpipe/actions/write/to/file_.py Data Manipulation drop Remove some keys from the input item Required Configuration - drop : # name or list of names of the keys to be removed Module source: openpipe/actions/drop_.py sort Sort items by keys Required Configuration - sort : key : # Name or list of names to use a group key Optional Configuration descendent : False # Use descendent order ? # It is possible to identify groups of repeated keys by setting # key_on_first. When it's set, the key will only be present on the # first item of a group items with the repeated key key_on_first : False Module source: openpipe/actions/sort_.py update Update values depending on conditional expressions Required Configuration - update : set : # Dictionary with keys/values to be updated Optional Configuration where : True # Expression to select items to be updated else : {} # Dictionary with keys/values to be updated when 'where' is False Module source: openpipe/actions/update_.py update using case replace Update field values using case match Required Configuration - update using case replace : # Dictionary with the updates rules: # # target_key_name: # target_key_value: expression # # Set target_key_name to target_key_value when expression evaluates # to True Module source: openpipe/actions/update/using/case/replace_.py update using key mapping Map values from source keys to values on target keys Required Configuration - update using key mapping : # Dictionary with the key mapping : # # target_key_name: # source_key_name: # old_value: new_value # # The action will set the \"target_key_name\" to \"new_value\" when the value # at source_key_name is equal to \"old_value\" Module source: openpipe/actions/update/using/key/mapping_.py update using string replace Replace some phrase with other phrase Required Configuration - update using string replace : # Dictionary with the replacement rules: # Replacement rules for a single string input item: # # { \"search_string\" : \"replace_string\", ... } # Replaces all occurrences of search_string with replace_string # # source_key_name: # \"search_string\" : \"replace_string\" # # In the 'source_key_name' value replaces all occurrences of # 'search_string' with 'replace_string' in the Module source: openpipe/actions/update/using/string/replace_.py Data Validation assert Asserts that input matches the config provided item Required Configuration - assert : # The item with the expected value(s) Module source: openpipe/actions/assert_.py","title":"Actions"},{"location":"1.0/actions/#data-sourcing","text":"","title":"Data Sourcing"},{"location":"1.0/actions/#empty","text":"Produce \"True\" when the input is empty Module source: openpipe/actions/empty_.py","title":"empty"},{"location":"1.0/actions/#execute","text":"Execute a command and produce the execution result Required Configuration - execute : cmd : # The command to be executed Optional Configuration shell : True # Execute the command as parameters to a system shell output_as_text : True # Output the command output as text fail_on_error : True # Abort pipeline if exit code is not zero Module source: openpipe/actions/execute_.py","title":"execute"},{"location":"1.0/actions/#insert","text":"Insert an item Required Configuration - insert : # Item to be produced as an output Module source: openpipe/actions/insert_.py","title":"insert"},{"location":"1.0/actions/#insert-path-split","text":"Split a path to 'directory' and 'file' components Optional Configuration - insert path split : '{ _ }' # The path to produce the director name from Module source: openpipe/actions/insert/path/split_.py","title":"insert path split"},{"location":"1.0/actions/#iterate","text":"Iterate the configuration item producing each element Optional Configuration - iterate : '{ _ }' # The item to be iterated over Module source: openpipe/actions/iterate_.py","title":"iterate"},{"location":"1.0/actions/#merge","text":"Merge input and configuration items Optional Configuration - merge : $_tag$ # The item to merge with Module source: openpipe/actions/merge_.py","title":"merge"},{"location":"1.0/actions/#queue","text":"Produce a list by queuing items Required Configuration - queue : The count of items to be queued before producing a list. If set to 0 all items are queued until the input ends Module source: openpipe/actions/queue_.py","title":"queue"},{"location":"1.0/actions/#read-from-clock","text":"Produce the system clock time at regular intervals Optional Configuration - read from clock : interval : 0 # Pause time between insertions, 0 means forever max_count : 1 # Max number of item insertions Module source: openpipe/actions/read/from/clock_.py","title":"read from clock"},{"location":"1.0/actions/#read-from-file","text":"Produce metadata/content from a local or remote file Required Configuration - read from file : path : # Local path or HTTP/HTTPS/FTP url Optional Configuration # The mime_type will be used by the action to identify and automatically # decode the file content. # With the default value of 'auto' the action will try to guess the # mime type based on the content header or file extension. mime_type : auto # The following option is only applicable to local filenames auto_expand_home : True # Expand '~' on path to user home dir Module source: openpipe/actions/read/from/file_.py","title":"read from file"},{"location":"1.0/actions/#read-from-file-list","text":"Produce the list of files matching a pattern Optional Configuration - read from file list : '{ _ }' # The pattern to be used for matching Module source: openpipe/actions/read/from/file/list_.py","title":"read from file list"},{"location":"1.0/actions/#read-from-file-status","text":"Get path status information Optional Configuration - read from file status : '{ _ }' # Path of the file to be checked Module source: openpipe/actions/read/from/file/status_.py","title":"read from file status"},{"location":"1.0/actions/#read-from-openpipe-actions","text":"Produce the list of available action actions Optional Configuration - read from openpipe actions : '{ _ }' # The item to be printed, the default is the input item Module source: openpipe/actions/read/from/openpipe/actions_.py","title":"read from openpipe actions"},{"location":"1.0/actions/#read-from-url","text":"Produce metadata/content from an URL Required Configuration - read from url : url : # HTTP/HTTPS/FTP url Optional Configuration # The mime_type will be used by the action to identify and automatically # decode the file content. # With the default value of 'auto' the action will try to guess the # mime type based on the content header or file extension. mime_type : auto # The following options are only relevant for HTTP/HTTPS/FTP paths timeout : 30 # Global timeout (in secs) for the operation ignore_http_errors : False # Ignore HTTP errors replies user_agent : curl/7.64.0 # User-agent to use on HTTP requests Module source: openpipe/actions/read/from/url_.py","title":"read from url"},{"location":"1.0/actions/#data-selection","text":"","title":"Data Selection"},{"location":"1.0/actions/#select","text":"Select input items based on a conditional expression Required Configuration - select : # Boolean Expression # Items are only copied to next action only when the expression evaluates # to True Module source: openpipe/actions/select_.py","title":"select"},{"location":"1.0/actions/#select-subset","text":"Select a subset of data from a dictionary input Required Configuration - select subset : # YAML describing the elements to be retrieved Module source: openpipe/actions/select/subset_.py","title":"select subset"},{"location":"1.0/actions/#data-transformation","text":"","title":"Data Transformation"},{"location":"1.0/actions/#decompress","text":"Decompress gzip input item Optional Configuration - decompress : path : \"\" # If not provided the input item is used type : gzip # the type to decompress Module source: openpipe/actions/decompress_.py","title":"decompress"},{"location":"1.0/actions/#reduce","text":"Reduce a complex item type into a simpler structure Optional Configuration - reduce : '{ _ }' # The target reduction format Module source: openpipe/actions/reduce_.py","title":"reduce"},{"location":"1.0/actions/#transform-using-csv","text":"Produce dictionary from CSV line based input Optional Configuration - transform using csv : delimiter : \",\" # One-character string used to separate fields quotechar : '\"' # One-character to wrap string values auto_number : False # Attempt to convert fields to numbers ignore_errors : False # Ignore conversion errors field_list : [] # Optional list of fields to be used as headers Module source: openpipe/actions/transform/using/csv_.py","title":"transform using csv"},{"location":"1.0/actions/#transform-using-regex-assign","text":"Build a dictionary from a key/map regex group expression Required Configuration - transform using regex assign : regex : # A regex expression that must match two groups: # (group1) (group2) Module source: openpipe/actions/transform/using/regex/assign_.py","title":"transform using regex assign"},{"location":"1.0/actions/#data-analysis","text":"","title":"Data Analysis"},{"location":"1.0/actions/#count","text":"Count the number of elements received Optional Configuration - count : group_by : \"\" # Expression to use for count aggregation Module source: openpipe/actions/count_.py","title":"count"},{"location":"1.0/actions/#group-by-stats","text":"Produce statistics by grouping input items by keys Required Configuration - group by stats : keys : # List of keys to be used for grouping Optional Configuration stats : [ sum , count , max , min ] # List of stats to obtain sorted_fields : [] # When these fields change, produce the sort Module source: openpipe/actions/group/by/stats_.py","title":"group by stats"},{"location":"1.0/actions/#pprint","text":"Pretty print an item Optional Configuration - pprint : '{ _ }' # The content to be pretty printed Module source: openpipe/actions/pprint_.py","title":"pprint"},{"location":"1.0/actions/#print","text":"Print an item Optional Configuration - print : \"{_}\" # The item to be printed, the default is the input item Module source: openpipe/actions/print_.py","title":"print"},{"location":"1.0/actions/#transform-using-terminaltables","text":"Produce a text table Required Configuration - transform using terminaltables : header : # List of labels to be used as column headers keys : # List of keys to be used or row elements Module source: openpipe/actions/transform/using/terminaltables_.py","title":"transform using terminaltables"},{"location":"1.0/actions/#data-control","text":"","title":"Data Control"},{"location":"1.0/actions/#limit","text":"Limit the max number of items sent to the next action Required Configuration - limit : max : # The max number of items sent to next action Module source: openpipe/actions/limit_.py","title":"limit"},{"location":"1.0/actions/#send-to-segment","text":"Send a copy of the input item to other segment(s) Required Configuration - send to segment : name : # Name or list of of segments to receive the item Optional Configuration when : \"\" # An expression that should result in a boolean # If `when` is set, item will only be copied to the segment(s) # when it evaluates to True. And sent to next action when it evaluates # to False Module source: openpipe/actions/send/to/segment_.py","title":"send to segment"},{"location":"1.0/actions/#tag","text":"Tag input item with the provided configuration tag item Optional Configuration - tag : '{ _ }' # Default is to tag the entire input item Module source: openpipe/actions/tag_.py","title":"tag"},{"location":"1.0/actions/#tag-key","text":"Tag a key or list of keys Required Configuration - tag key : name : # The name or list of names for the keys to be tagged Module source: openpipe/actions/tag/key_.py","title":"tag key"},{"location":"1.0/actions/#data-export","text":"","title":"Data Export"},{"location":"1.0/actions/#write-to-file","text":"Write item to a file Required Configuration - write to file : path : # Filename of the file to create/overwrite/append Optional Configuration content : '{ _ }' # Content to be written to the file mode : \"w\" # Open file mode (write/append) close_on_item : False # Force file close after each received item Module source: openpipe/actions/write/to/file_.py","title":"write to file"},{"location":"1.0/actions/#data-manipulation","text":"","title":"Data Manipulation"},{"location":"1.0/actions/#drop","text":"Remove some keys from the input item Required Configuration - drop : # name or list of names of the keys to be removed Module source: openpipe/actions/drop_.py","title":"drop"},{"location":"1.0/actions/#sort","text":"Sort items by keys Required Configuration - sort : key : # Name or list of names to use a group key Optional Configuration descendent : False # Use descendent order ? # It is possible to identify groups of repeated keys by setting # key_on_first. When it's set, the key will only be present on the # first item of a group items with the repeated key key_on_first : False Module source: openpipe/actions/sort_.py","title":"sort"},{"location":"1.0/actions/#update","text":"Update values depending on conditional expressions Required Configuration - update : set : # Dictionary with keys/values to be updated Optional Configuration where : True # Expression to select items to be updated else : {} # Dictionary with keys/values to be updated when 'where' is False Module source: openpipe/actions/update_.py","title":"update"},{"location":"1.0/actions/#update-using-case-replace","text":"Update field values using case match Required Configuration - update using case replace : # Dictionary with the updates rules: # # target_key_name: # target_key_value: expression # # Set target_key_name to target_key_value when expression evaluates # to True Module source: openpipe/actions/update/using/case/replace_.py","title":"update using case replace"},{"location":"1.0/actions/#update-using-key-mapping","text":"Map values from source keys to values on target keys Required Configuration - update using key mapping : # Dictionary with the key mapping : # # target_key_name: # source_key_name: # old_value: new_value # # The action will set the \"target_key_name\" to \"new_value\" when the value # at source_key_name is equal to \"old_value\" Module source: openpipe/actions/update/using/key/mapping_.py","title":"update using key mapping"},{"location":"1.0/actions/#update-using-string-replace","text":"Replace some phrase with other phrase Required Configuration - update using string replace : # Dictionary with the replacement rules: # Replacement rules for a single string input item: # # { \"search_string\" : \"replace_string\", ... } # Replaces all occurrences of search_string with replace_string # # source_key_name: # \"search_string\" : \"replace_string\" # # In the 'source_key_name' value replaces all occurrences of # 'search_string' with 'replace_string' in the Module source: openpipe/actions/update/using/string/replace_.py","title":"update using string replace"},{"location":"1.0/actions/#data-validation","text":"","title":"Data Validation"},{"location":"1.0/actions/#assert","text":"Asserts that input matches the config provided item Required Configuration - assert : # The item with the expected value(s) Module source: openpipe/actions/assert_.py","title":"assert"},{"location":"1.0/language/","text":"Data Pipeline Language Introduction This page describes the syntax and core concepts of the data pipeline language , an human friendly data-oriented language that can be used to describe data transformation workflows for both structured and unstructured data. DPL does not replace technology specific languages (e.g. SQL), instead it provides an higher level computable language capable of integrating data from diverse formats, sources and technology. Prerequisites DPL is entirely based on the YAML format. The knowledge of YAML is fundamental for the proper understanding of the material in this document. While in general the data processing operations will be described using markup language, when calculations and transformations are needed, a good understanding of Python's Standard Data Types and Operations is required. Concepts Pipeline DPL follows the data pipeline design pattern: a set of data processing elements connected in series, where the output of one element is the input of the next one. In DPL the elements are referred as actions* , and a sequence of actions is referred as a segment***. A pipeline document is a single YAML document that contains one or more segments. Segments A segment must be represented by a dictionary, where the key is the segment name and the value is a sequence of actions. _segment name Segment names started with \"_\" will not be loaded. They can be used to store configuration to be referenced with YAML anchors. The _libraries segment name has a special purpose explained later on this document. Actions An action must be represented by a dictionary, where the key is an action name and the value contains the action config, config may be of any of the YAML supported data types. Example pipeline.yaml # This is the 'start' segment start : # Call the \"print\" action with the config string Hello World! - print : Hello World! Output: Hello World! The start segment Runnable pipelines must contain a segment named start . The first operation in that segment will receive a single input item with openpipe run arguments. Multiple Segments A single pipeline may need to produce distinct outputs from the same input data, in order to support this some actions can send data to other segments. Integrated Development Environment At this time there is no specialized IDE for pipeline editing, any general purpose IDE with a good support for YAML is suitable. Workflow Execution Document Loading The command line tool openpipe is the software that reads a pipeline document file, loads it into the execution engine and activates the workflow. Action Modules The execution engine loads the action modules associated with action names, and creates action instances for every action defined in the pipeline. Action modules can provide a wide range of action types: collection, filtering, exporting, etc. You can get the list of available actions with: openpipe help You can get the help for an action with: openpipe help \u00abaction\u00bb Data Items In DPL any kind of workflow managed data is referred as an item , in openpipe items are stored in memory and transmitted as Python object references, as such, items can be of any data type or class available with Python. Data Flow Action instances should be observed as independent processing units, the following items will be available to them: Input Item: the input data provided to the action Config Item: the config data that is based on the user provided config Output Item: output data produced by the action execution Tag Item: the tag Output -> Input As a general rule the output item of a action will be the input item of the next action in the same segment, with the exception of the send to action that can deliver items to the first action of other segments. Last Action Output Items Output items from the last action in a segment will be silently discarded. Dynamic Configuration Action configuration items provided in the pipeline document, can include dynamic components. When an action is executed due to the reception of an input item, it's configuration is updated to reflect any changes in the input. This feature provides the ability to embed python expressions and action input data on it's configuration. Before invoking the action input handling, any config text found between consecutive dollar signs ($) will be evaluated as a python expression and replaced with it's result. If you need to have '$' in your string, you will need to escape it using \\$ . During expression evaluation, the \"_\" symbol is a reference to the full input item. When the input item is a dict, it's keys values will be mapped to variable names so that you can refer to them easily by providing $key$. Important Several actions use a default configuration of '{ _ }' which means the full input item will be used as the configuration item. It is the case of the print and assert actions. Examples: calc.yaml start : - print : 2 + 1 = $2 + 1$ # Print a sum result Output: 2 + 1 = 3 input_item.yaml start : - insert : place : zoo - print : '{ _ }' # Print the full input item input_field.yaml start : - insert : animal : Elephant size : big - print : The $animal$ is $size$. # Print some fields Output: The Elephant is big. Data Tagging One of the challenges of using independent pipeline actions with a strict input/output pattern is the need to correlate/aggregate outputs from different actions. Openpipe addresses this with the support for data tagging. Items flowing through a pipeline can be tagged, a tag is a piece of information that will be transmitted with every item as it is sent to the _after tagging actions in the pipeline. Let's assume as example that we want to produce the count of 'a' letters from a list of files: start : - iterate : [ /etc/passwd , /etc/group ] - read from file : '{ _ }' # The read from file outputs only the file content, we can't refer to # the file name anymore - print : The number of 'a's in file is $ _.count(b'a') $ In order to persist the file name, we need to tag it before the the read from file action. After being tagged, we can refer to it with the special reference $_tag$ : start : - iterate : [ /etc/passwd , /etc/group ] - tag : '{ _ }' # The filename is tagged, tag is available on every next action - read from file : '{ _ }' # We can now use $_tag_ - print : The number of 'a's in file $_tag$ is $ _.count(b'a') $ When more than two items need to be tagged, a dictionary based tag needs to be used, every tag will be merged into the tag dict. # do some action tag : { animal_type : '{ _ }' } # Tag it as animal type # do some other action tag : { animal_size : '{ _ }' } # Tag it as animal size # We can now use $_tag['animal_type']$ and $_tag['animal_size']$ Action Libraries A pipeline may contain a special segment named _libraries . This segment must contain a list of local directories or urls for libraries containing additional actions. Copyright and License \u00a9 2019 CCS Group International This document is distributed under the Creative Commons Attribution 4.0 International License .","title":"Language"},{"location":"1.0/language/#data-pipeline-language","text":"","title":"Data Pipeline Language"},{"location":"1.0/language/#introduction","text":"This page describes the syntax and core concepts of the data pipeline language , an human friendly data-oriented language that can be used to describe data transformation workflows for both structured and unstructured data. DPL does not replace technology specific languages (e.g. SQL), instead it provides an higher level computable language capable of integrating data from diverse formats, sources and technology.","title":"Introduction"},{"location":"1.0/language/#prerequisites","text":"DPL is entirely based on the YAML format. The knowledge of YAML is fundamental for the proper understanding of the material in this document. While in general the data processing operations will be described using markup language, when calculations and transformations are needed, a good understanding of Python's Standard Data Types and Operations is required.","title":"Prerequisites"},{"location":"1.0/language/#concepts","text":"","title":"Concepts"},{"location":"1.0/language/#pipeline","text":"DPL follows the data pipeline design pattern: a set of data processing elements connected in series, where the output of one element is the input of the next one. In DPL the elements are referred as actions* , and a sequence of actions is referred as a segment***. A pipeline document is a single YAML document that contains one or more segments.","title":"Pipeline"},{"location":"1.0/language/#segments","text":"A segment must be represented by a dictionary, where the key is the segment name and the value is a sequence of actions. _segment name Segment names started with \"_\" will not be loaded. They can be used to store configuration to be referenced with YAML anchors. The _libraries segment name has a special purpose explained later on this document.","title":"Segments"},{"location":"1.0/language/#actions","text":"An action must be represented by a dictionary, where the key is an action name and the value contains the action config, config may be of any of the YAML supported data types.","title":"Actions"},{"location":"1.0/language/#example","text":"pipeline.yaml # This is the 'start' segment start : # Call the \"print\" action with the config string Hello World! - print : Hello World! Output: Hello World! The start segment Runnable pipelines must contain a segment named start . The first operation in that segment will receive a single input item with openpipe run arguments.","title":"Example"},{"location":"1.0/language/#multiple-segments","text":"A single pipeline may need to produce distinct outputs from the same input data, in order to support this some actions can send data to other segments.","title":"Multiple Segments"},{"location":"1.0/language/#integrated-development-environment","text":"At this time there is no specialized IDE for pipeline editing, any general purpose IDE with a good support for YAML is suitable.","title":"Integrated Development Environment"},{"location":"1.0/language/#workflow-execution","text":"","title":"Workflow Execution"},{"location":"1.0/language/#document-loading","text":"The command line tool openpipe is the software that reads a pipeline document file, loads it into the execution engine and activates the workflow.","title":"Document Loading"},{"location":"1.0/language/#action-modules","text":"The execution engine loads the action modules associated with action names, and creates action instances for every action defined in the pipeline. Action modules can provide a wide range of action types: collection, filtering, exporting, etc. You can get the list of available actions with: openpipe help You can get the help for an action with: openpipe help \u00abaction\u00bb","title":"Action Modules"},{"location":"1.0/language/#data-items","text":"In DPL any kind of workflow managed data is referred as an item , in openpipe items are stored in memory and transmitted as Python object references, as such, items can be of any data type or class available with Python.","title":"Data Items"},{"location":"1.0/language/#data-flow","text":"Action instances should be observed as independent processing units, the following items will be available to them: Input Item: the input data provided to the action Config Item: the config data that is based on the user provided config Output Item: output data produced by the action execution Tag Item: the tag Output -> Input As a general rule the output item of a action will be the input item of the next action in the same segment, with the exception of the send to action that can deliver items to the first action of other segments. Last Action Output Items Output items from the last action in a segment will be silently discarded.","title":"Data Flow"},{"location":"1.0/language/#dynamic-configuration","text":"Action configuration items provided in the pipeline document, can include dynamic components. When an action is executed due to the reception of an input item, it's configuration is updated to reflect any changes in the input. This feature provides the ability to embed python expressions and action input data on it's configuration. Before invoking the action input handling, any config text found between consecutive dollar signs ($) will be evaluated as a python expression and replaced with it's result. If you need to have '$' in your string, you will need to escape it using \\$ . During expression evaluation, the \"_\" symbol is a reference to the full input item. When the input item is a dict, it's keys values will be mapped to variable names so that you can refer to them easily by providing $key$. Important Several actions use a default configuration of '{ _ }' which means the full input item will be used as the configuration item. It is the case of the print and assert actions. Examples: calc.yaml start : - print : 2 + 1 = $2 + 1$ # Print a sum result Output: 2 + 1 = 3 input_item.yaml start : - insert : place : zoo - print : '{ _ }' # Print the full input item input_field.yaml start : - insert : animal : Elephant size : big - print : The $animal$ is $size$. # Print some fields Output: The Elephant is big.","title":"Dynamic Configuration"},{"location":"1.0/language/#data-tagging","text":"One of the challenges of using independent pipeline actions with a strict input/output pattern is the need to correlate/aggregate outputs from different actions. Openpipe addresses this with the support for data tagging. Items flowing through a pipeline can be tagged, a tag is a piece of information that will be transmitted with every item as it is sent to the _after tagging actions in the pipeline. Let's assume as example that we want to produce the count of 'a' letters from a list of files: start : - iterate : [ /etc/passwd , /etc/group ] - read from file : '{ _ }' # The read from file outputs only the file content, we can't refer to # the file name anymore - print : The number of 'a's in file is $ _.count(b'a') $ In order to persist the file name, we need to tag it before the the read from file action. After being tagged, we can refer to it with the special reference $_tag$ : start : - iterate : [ /etc/passwd , /etc/group ] - tag : '{ _ }' # The filename is tagged, tag is available on every next action - read from file : '{ _ }' # We can now use $_tag_ - print : The number of 'a's in file $_tag$ is $ _.count(b'a') $ When more than two items need to be tagged, a dictionary based tag needs to be used, every tag will be merged into the tag dict. # do some action tag : { animal_type : '{ _ }' } # Tag it as animal type # do some other action tag : { animal_size : '{ _ }' } # Tag it as animal size # We can now use $_tag['animal_type']$ and $_tag['animal_size']$","title":"Data Tagging"},{"location":"1.0/language/#action-libraries","text":"A pipeline may contain a special segment named _libraries . This segment must contain a list of local directories or urls for libraries containing additional actions.","title":"Action Libraries"},{"location":"1.0/language/#copyright-and-license","text":"\u00a9 2019 CCS Group International This document is distributed under the Creative Commons Attribution 4.0 International License .","title":"Copyright and License"},{"location":"1.0/openpipe-runtime/","text":"Runtime Engine (openpipe) Once you are familiar with the pipeline format as described on the previous sections, it is important to understand the purpose of the OPL runtime engine. An OPL runtime engine is the software responsible for: Loading, parsing and validating pipeline documents Mapping action names to computer functions (code) Validating action config versus the specific action requirements Allocate instances for each action of the pipeline Establishing the \"connections\" between steps Delivering the system current time to the first action of the 'start' segment Scheduling the action code execution when input data becomes available","title":"Openpipe runtime"},{"location":"1.0/openpipe-runtime/#runtime-engine-openpipe","text":"Once you are familiar with the pipeline format as described on the previous sections, it is important to understand the purpose of the OPL runtime engine. An OPL runtime engine is the software responsible for: Loading, parsing and validating pipeline documents Mapping action names to computer functions (code) Validating action config versus the specific action requirements Allocate instances for each action of the pipeline Establishing the \"connections\" between steps Delivering the system current time to the first action of the 'start' segment Scheduling the action code execution when input data becomes available","title":"Runtime Engine (openpipe)"},{"location":"1.0/tool/","text":"Openpipe Tool Introduction The openpipe tool is a command line utility which runs on Linux, Mac and Windows and can be used to collect, transform and analyse data from multiple sources. In order to use openpipe, you must either adapt existing pipeline examples, or create your own data pipelines, in any case it is strongly recommended that you read the DPL language documentation . Requirements In order to use openpipe you must have Python 3 with pip installed. If you are using Windows and need help use the Windows Python 3 install guide, if you are using Linux follow the appropriate instructions for your Linux distribution. Install Open a command line prompt/terminal and install the openpipe package: pip install --user --upgrade openpipe Getting Started Using your preferred text editor, create a file named pipeline.yaml with the following content: # This is a simple example that pretty prints the content of a remote JSON file start : - read from url : https://api.exchangeratesapi.io/latest - pprint : Then just run the pipeline using: openpipe run pipeline.yaml To get a list of the action actions available in the standard library, run: openpipe help To get the help/example for a specific action, run: openpipe help action name Example: openpipe help print Extra Actions Libraries Openpipe supports additional actions libraries, you can check for available libraries with: openpipe list-actions-lib Install the required library with: openpipe install-actions-lib \u00ablibrary_name\u00bb Action libraries are maintained on GitHub repositories under the openpipe-extra-actions organization.","title":"Tool"},{"location":"1.0/tool/#openpipe-tool","text":"","title":"Openpipe Tool"},{"location":"1.0/tool/#introduction","text":"The openpipe tool is a command line utility which runs on Linux, Mac and Windows and can be used to collect, transform and analyse data from multiple sources. In order to use openpipe, you must either adapt existing pipeline examples, or create your own data pipelines, in any case it is strongly recommended that you read the DPL language documentation .","title":"Introduction"},{"location":"1.0/tool/#requirements","text":"In order to use openpipe you must have Python 3 with pip installed. If you are using Windows and need help use the Windows Python 3 install guide, if you are using Linux follow the appropriate instructions for your Linux distribution.","title":"Requirements"},{"location":"1.0/tool/#install","text":"Open a command line prompt/terminal and install the openpipe package: pip install --user --upgrade openpipe","title":"Install"},{"location":"1.0/tool/#getting-started","text":"Using your preferred text editor, create a file named pipeline.yaml with the following content: # This is a simple example that pretty prints the content of a remote JSON file start : - read from url : https://api.exchangeratesapi.io/latest - pprint : Then just run the pipeline using: openpipe run pipeline.yaml To get a list of the action actions available in the standard library, run: openpipe help To get the help/example for a specific action, run: openpipe help action name Example: openpipe help print","title":"Getting Started"},{"location":"1.0/tool/#extra-actions-libraries","text":"Openpipe supports additional actions libraries, you can check for available libraries with: openpipe list-actions-lib Install the required library with: openpipe install-actions-lib \u00ablibrary_name\u00bb Action libraries are maintained on GitHub repositories under the openpipe-extra-actions organization.","title":"Extra Actions Libraries"}]}